activation: tanh
alpha: 0.001
beta_1: 0.9
beta_2: 0.999
epsilon: 1e-09
hidden_layer_sizes: (50, 50, 50)
learning_rate: constant
learning_rate_init: 0.1
max_iter: 300
momentum: 0.8
n_iter_no_change: 10
power_t: 0.6
solver: adam
准确度: 0.67